
Background:
Our infrastructure uses ZFS for storage, but there's currently no integration with Datadog for visibility into ZFS pool health, device-level errors, or usage statistics. Lack of monitoring could lead to silent degradation or failures.

This task sets up a custom Datadog Agent check to monitor ZFS health, capacity, and error rates using a Python script.

Acceptance Criteria:
- [ ] Deploy custom check script to Datadog agent host(s)
- [ ] Monitor:
  - Pool state (ONLINE, DEGRADED, etc.)
  - Capacity: allocated, free, and total
  - Device read/write errors
- [ ] Define service checks:
  - zfs.pool.health with OK/WARNING/CRITICAL based on state
- [ ] Define metrics:
  - zfs.pool.size, zfs.pool.allocated, zfs.pool.free
  - zfs.device.read_errors, zfs.device.write_errors
  - zfs.pool.health.status_code
- [ ] Add meaningful tags: pool:<name>, device:<name>
- [ ] Validate data in Datadog Metrics Explorer and Service Checks

Example Configuration:

zfs_check.py:
(Use the full script provided in the ticket)

zfs_check.yaml:
init_config:

instances:
  - name: zfs_monitor
    tags:
      - env:prod
    min_collection_interval: 60

Monitoring Alerts:
| Condition                                | Datadog Monitor Type | Severity   |
|------------------------------------------|------------------------|------------|
| Pool state != ONLINE                     | Service Check          | Critical   |
| Pool usage exceeds 85%                   | Metric Threshold       | Warning    |
| Device read/write errors > 0             | Metric Threshold       | Warning    |
